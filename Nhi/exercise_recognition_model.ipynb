{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set_num</th>\n",
       "      <th>activity</th>\n",
       "      <th>time</th>\n",
       "      <th>x_gyro</th>\n",
       "      <th>y_gyro</th>\n",
       "      <th>z_gyro</th>\n",
       "      <th>x_acc</th>\n",
       "      <th>y_acc</th>\n",
       "      <th>z_acc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Band Pull-Down Row</td>\n",
       "      <td>676.115485</td>\n",
       "      <td>-15.147634</td>\n",
       "      <td>23.954241</td>\n",
       "      <td>14.705304</td>\n",
       "      <td>0.356986</td>\n",
       "      <td>-0.823410</td>\n",
       "      <td>-0.031189</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Band Pull-Down Row</td>\n",
       "      <td>679.055465</td>\n",
       "      <td>-148.993389</td>\n",
       "      <td>-1.727050</td>\n",
       "      <td>-8.243589</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>-0.887622</td>\n",
       "      <td>-0.215872</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Band Pull-Down Row</td>\n",
       "      <td>679.615462</td>\n",
       "      <td>147.988473</td>\n",
       "      <td>3.768917</td>\n",
       "      <td>95.452735</td>\n",
       "      <td>0.557560</td>\n",
       "      <td>-1.130520</td>\n",
       "      <td>0.688100</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Band Pull-Down Row</td>\n",
       "      <td>681.575448</td>\n",
       "      <td>-140.093738</td>\n",
       "      <td>-29.372863</td>\n",
       "      <td>32.133631</td>\n",
       "      <td>0.448862</td>\n",
       "      <td>-0.735180</td>\n",
       "      <td>0.236496</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Band Pull-Down Row</td>\n",
       "      <td>684.775427</td>\n",
       "      <td>-21.686398</td>\n",
       "      <td>-1.344477</td>\n",
       "      <td>-0.517016</td>\n",
       "      <td>0.367619</td>\n",
       "      <td>-0.557327</td>\n",
       "      <td>0.755909</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   set_num            activity        time      x_gyro     y_gyro     z_gyro  \\\n",
       "0        0  Band Pull-Down Row  676.115485  -15.147634  23.954241  14.705304   \n",
       "1        0  Band Pull-Down Row  679.055465 -148.993389  -1.727050  -8.243589   \n",
       "2        0  Band Pull-Down Row  679.615462  147.988473   3.768917  95.452735   \n",
       "3        0  Band Pull-Down Row  681.575448 -140.093738 -29.372863  32.133631   \n",
       "4        0  Band Pull-Down Row  684.775427  -21.686398  -1.344477  -0.517016   \n",
       "\n",
       "      x_acc     y_acc     z_acc  label  \n",
       "0  0.356986 -0.823410 -0.031189   46.0  \n",
       "1  0.019032 -0.887622 -0.215872   46.0  \n",
       "2  0.557560 -1.130520  0.688100   46.0  \n",
       "3  0.448862 -0.735180  0.236496   46.0  \n",
       "4  0.367619 -0.557327  0.755909   46.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data_file_path = 'data/exercise_recognition_data.csv'\n",
    "df = pd.read_csv(data_file_path)\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df[['set_num', 'time', 'x_gyro', 'y_gyro', 'z_gyro', 'x_acc', 'y_acc', 'z_acc']]\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up GPU\n",
    "Follow instruction to set up gpu5: https://medium.com/@mromerocalvo/set-up-a-remote-machine-for-deep-learning-with-jupyter-notebook-1946729f9fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# this ensures that the current current PyTorch installation was built with MPS activated\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR'] = '0.0.0.0'\n",
    "os.environ['MASTER_PORT'] = '8888'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['RANK'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the GPU device ID\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "Define the architecture of the deep learning model.\n",
    "- Setting the hidden_size to 128 is a common practice in deep learning. It is a reasonable starting point that strikes a balance between model capacity and computational efficiency.\n",
    "- In this case, the task is to predict the exercise (activity) name from the given sensor data. Since this is a multi-class classification problem with more than two possible activity labels, the CrossEntropyLoss function is a suitable choice for the loss function.\n",
    "- Adam (Adaptive Moment Estimation) is a suitable optimizer because of several reasons:\n",
    "  - In exercise recognition tasks, different activities may have different levels of complexity and variations in their sensor data. The adaptive learning rate of Adam allows the model to dynamically adjust the learning rate for each parameter, leading to faster convergence and potentially better generalization.\n",
    "  - Adam incorporates momentum, which helps accelerate the training process by allowing the optimizer to accumulate past gradients and move in the relevant directions with more speed. This can be particularly useful in exercise recognition tasks where the model needs to capture temporal dependencies in the sensor data. The momentum term in Adam can assist in better capturing the patterns and dynamics of the exercises.\n",
    "  - In exercise recognition tasks, it is common for certain sensor data points to have sparse gradients. For example, there might be instances where the sensor data does not change significantly over time for certain activities. Adam's ability to handle sparse gradients makes it a suitable optimizer for such cases, ensuring stable and effective training even when some gradients are infrequent or noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32, device=device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long, device=device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32, device=device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch dataset and dataloader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the deep learning model architecture\n",
    "class ExerciseClassifier1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ExerciseClassifier1, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3357\n",
      "Epoch 2/10, Loss: 1.2267\n",
      "Epoch 3/10, Loss: 1.2069\n",
      "Epoch 4/10, Loss: 1.2000\n",
      "Epoch 5/10, Loss: 1.2018\n",
      "Epoch 6/10, Loss: 1.1955\n",
      "Epoch 7/10, Loss: 1.1912\n",
      "Epoch 8/10, Loss: 1.1916\n",
      "Epoch 9/10, Loss: 1.1896\n",
      "Epoch 10/10, Loss: 1.1936\n"
     ]
    }
   ],
   "source": [
    "# Set the hyperparameters\n",
    "input_size = len(X_train)\n",
    "hidden_size = 128\n",
    "num_classes = len(df.activity.unique())\n",
    "\n",
    "# Initialize the model\n",
    "model1 = ExerciseClassifier1(input_size, hidden_size, num_classes)\n",
    "model1.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.01)\n",
    "\n",
    "# Train the deep learning model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model1.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model1(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "1. Use the trained model to make predictions on the testing dataset.\n",
    "2. Evaluate the performance of the model using accuracy as performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6419440529686454\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model1.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model1(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy1 = correct / total\n",
    "print('Test Accuracy:', test_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the entire model (including architecture and parameters)\n",
    "torch.save(model1, 'models/model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
